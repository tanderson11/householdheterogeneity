{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thayer/develop/covid_households\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69718585, 0.70149867],\n",
       "       [0.19865032, 0.20241626],\n",
       "       [0.04931836, 0.05137486],\n",
       "       [0.03883804, 0.04067565],\n",
       "       [0.00958512, 0.01052321]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confidence intervals for multinomial outcomes sampled however many times\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.stats.proportion as smprop\n",
    "\n",
    "p=np.array([0.7,0.2,0.05,0.04,0.01])\n",
    "counts = np.array(np.unique(np.random.choice(5,300000,p=p), return_counts=True)).T[:,1]\n",
    "smprop.multinomial_proportions_confint(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24695378, 0.25127474],\n",
       "       [0.24802664, 0.25235382],\n",
       "       [0.24717713, 0.25149938],\n",
       "       [0.24921519, 0.25354922]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = np.array(np.unique(np.random.choice(4,250000,), return_counts=True)).T[:,1]\n",
    "smprop.multinomial_proportions_confint(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.recipes as recipes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('mode.chained_assignment', 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcomplete\u001b[m\u001b[m                          trials-10-powers-23-09-21.xlsx\n",
      "fine_grain_sar.parquet            trials-10-powers-23-09-23.xlsx\n",
      "\u001b[34mparts\u001b[m\u001b[m                             trials-300-powers-23-09-55.xlsx\n",
      "trials-10-powers-23-09-08.xlsx    trials-300-powers-24-13-59.xlsx\n",
      "trials-10-powers-23-09-11.xlsx    ~$trials-300-powers-23-09-55.xlsx\n",
      "trials-10-powers-23-09-14.xlsx\n"
     ]
    }
   ],
   "source": [
    "!ls ./epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = recipes.Results.load('./epidemics/final', 'fine_grain_sar.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s80   p80   SAR   size  infections\n",
       "0.02  0.02  0.01  2     1             0.997812\n",
       "                        2             0.002188\n",
       "                  3     1             0.994432\n",
       "                        2             0.005052\n",
       "                        3             0.000516\n",
       "                                        ...   \n",
       "0.80  0.80  0.60  3     3             0.761556\n",
       "                  4     1             0.081860\n",
       "                        2             0.010840\n",
       "                        3             0.014612\n",
       "                        4             0.892688\n",
       "Name: count, Length: 1713577, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.find_frequencies(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_parameters(base_results, included_parameters):\n",
    "    freqs = base_results.df['frequency'].copy()\n",
    "\n",
    "    for parameter in set(base_results.metadata.parameters) - set(included_parameters):\n",
    "        if parameter not in ['s80', 'p80']:\n",
    "            raise ValueError(\"can't exclude SAR as it has no default hypothesis.\")\n",
    "        parameter_level = freqs.index.get_level_values(base_results.metadata.parameters.index(parameter))\n",
    "        freqs = freqs[(parameter_level == 0.8)]\n",
    "\n",
    "    return freqs\n",
    "\n",
    "def restrict_on_sizes(frequencies, included_sizes):\n",
    "    frequencies = frequencies[frequencies.index.get_level_values('size').isin(included_sizes)]\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.likelihood as likelihood\n",
    "\n",
    "def SAR_pvalue_for_trial(baseline_logl, comparison_logl, for_increase=False):\n",
    "    baseline_posterior = np.exp(baseline_logl.sort_values(ascending=False)-baseline_logl.max())\n",
    "    baseline_posterior = baseline_posterior/baseline_posterior.sum()\n",
    "    # we groupby 'SAR' and sum so that we can capture all the probability at that SAR — regardless of other parameter values\n",
    "    baseline_probability_over_sars = baseline_posterior.groupby('SAR').sum()\n",
    "\n",
    "    comparison_posterior = np.exp(comparison_logl.sort_values(ascending=False)-comparison_logl.max())\n",
    "    #print(baseline_logl.idxmax(), comparison_logl.idxmax())\n",
    "    #if baseline_logl.idxmax()[3] == 0.01:\n",
    "    #    import pdb; pdb.set_trace()\n",
    "    #import pdb; pdb.set_trace()\n",
    "    baseline_SAR_confidence_interval = likelihood.confidence_interval_from_confidence_mask(likelihood.confidence_mask_from_logl(baseline_logl, percentiles=(0.9,)), key='SAR')\n",
    "    comparison_SAR_confidence_interval = likelihood.confidence_interval_from_confidence_mask(likelihood.confidence_mask_from_logl(comparison_logl, percentiles=(0.9,)), key='SAR')\n",
    "    comparison_posterior = comparison_posterior/comparison_posterior.sum()\n",
    "    probability_over_sars = comparison_posterior.groupby('SAR').sum()\n",
    "\n",
    "    # use the probability surface to generate imagined MLEs\n",
    "    sample1 = np.random.choice(baseline_probability_over_sars.index, 10000, p=baseline_probability_over_sars)\n",
    "    sample2 = np.random.choice(probability_over_sars.index, 10000, p=probability_over_sars)\n",
    "\n",
    "    # what fraction of the time does the first group have a increased/decreased SAR compared to the second group\n",
    "    if for_increase:\n",
    "        pvalue = np.count_nonzero((sample2-sample1) > 0)/len(sample1)\n",
    "    else:\n",
    "        pvalue = np.count_nonzero((sample2-sample1) < 0)/len(sample1)\n",
    "\n",
    "    return pvalue, baseline_SAR_confidence_interval, comparison_SAR_confidence_interval\n",
    "\n",
    "interval_notes = defaultdict(list)\n",
    "\n",
    "def calculate_power_over_SAR_range(population, trials, basline_parameters, sar_range, hypotheses, frequencies_by_hypothesis, for_increase=False):\n",
    "    pvalue_sets = []\n",
    "    for hypothesis_name in hypotheses.keys():\n",
    "        frequencies = frequencies_by_hypothesis[hypothesis_name]\n",
    "        for sar in sar_range:\n",
    "            # replace baseline sar with target sar\n",
    "            parameters = list(basline_parameters)\n",
    "            parameters[results.metadata.parameters.index('SAR')] = float(f'{sar:0.3f}')\n",
    "            parameters = tuple(parameters)\n",
    "            #print(parameters)\n",
    "   \n",
    "            # get imagined infections from the simulated data at the baseline parameters to establish the probability surface for the MLE w.r.t. the baseline\n",
    "            samples = results.resample(basline_parameters, population, trials=trials)\n",
    "            baseline_logl = likelihood.logl_from_frequencies_and_counts(frequencies, samples['count'], results.metadata.parameters)\n",
    "\n",
    "            # get imagined infections from the simulated data at the comparison parameters to establish the probability surface for the MLE w.r.t. the comparison point\n",
    "            samples = results.resample(parameters, population, trials=trials)\n",
    "            logl = likelihood.logl_from_frequencies_and_counts(frequencies, samples['count'], results.metadata.parameters)\n",
    "\n",
    "            comparison_logl_grouped = logl.groupby('trial')\n",
    "            single_trial_pvalues = []\n",
    "            for key, baseline_logl_trial_group in baseline_logl.groupby('trial'):\n",
    "                comparison_logl_trial_group = comparison_logl_grouped.get_group(key)\n",
    "                pvalue, baseline_SAR_confidence_interval, comparison_SAR_confidence_interval = SAR_pvalue_for_trial(baseline_logl_trial_group, comparison_logl_trial_group, for_increase=for_increase)\n",
    "                single_trial_pvalues.append(pvalue)\n",
    "            #index = pd.MultiIndex.from_product([sar, hypothesis_name, list(range(trials))], names=['SAR', 'hypothesis', 'trial'])\n",
    "            #pvalue_sets.append(pd.Series(data=single_trial_pvalues, index=index))\n",
    "            pvalue_sets.append(pd.DataFrame({'pvalue':single_trial_pvalues, 'SAR':sar, 'hypothesis':hypothesis_name, 'trial':list(range(trials))}))\n",
    "    df_piece = pd.concat(pvalue_sets)\n",
    "    return df_piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4}\n",
      "{2: 36, 3: 24, 4: 18}\n",
      "{2: 36, 3: 24, 4: 18}\n"
     ]
    }
   ],
   "source": [
    "sar_range = np.linspace(0.10, 0.25, 4)\n",
    "trials = 300\n",
    "power_pvalue = 0.9\n",
    "\n",
    "# no, medium, and high heterogeneity as defined in the paper\n",
    "baseline_parameter_sets = [\n",
    "    (0.8, 0.8, 0.25),\n",
    "    (0.8, 0.2, 0.25),\n",
    "    #(0.5, 0.5, 0.25),\n",
    "    #(0.2, 0.2, 0.25),\n",
    "]\n",
    "\n",
    "# target population = 216 (divisible by 36)\n",
    "populations = [\n",
    "    {2: 36, 3:24, 4:18},\n",
    "]\n",
    "\n",
    "for p in populations:\n",
    "    assert sum([k*v for k,v in p.items()]) == 216\n",
    "\n",
    "all_sizes = set()\n",
    "for p in populations:\n",
    "    all_sizes = all_sizes.union(set(p.keys()))\n",
    "\n",
    "print(all_sizes)\n",
    "\n",
    "hypotheses = {\n",
    "    'all': ['s80', 'p80', 'SAR'],\n",
    "    'inf-and-SAR-vary': ['p80', 'SAR'],\n",
    "    'sus-and-SAR-vary': ['s80', 'SAR'],\n",
    "    'only-SAR-varies': ['SAR'],\n",
    "}\n",
    "frequencies_by_hypothesis = {k: restrict_parameters(results, included_parameters) for k,included_parameters in hypotheses.items()}\n",
    "\n",
    "frequencies_by_hypothesis = {k: restrict_on_sizes(f, all_sizes) for k,f in frequencies_by_hypothesis.items()}\n",
    "\n",
    "\n",
    "pvalue_dfs = []\n",
    "power_dfs = defaultdict(list)\n",
    "\n",
    "pvalue_df_pieces = []\n",
    "for baseline_parameters in baseline_parameter_sets:\n",
    "    for population in populations:\n",
    "        print(population)\n",
    "        pvalue_df_piece = calculate_power_over_SAR_range(population, trials, baseline_parameters, sar_range, hypotheses, frequencies_by_hypothesis)\n",
    "        pvalue_df_piece['parameters'] = str(baseline_parameters)\n",
    "        pvalue_df_piece['population'] = str(population)\n",
    "        #print(pvalue_df_piece)\n",
    "        pvalue_df_pieces.append(pvalue_df_piece)\n",
    "        #pvalue_df = pd.DataFrame(pvalues_for_decrease, index=[float(f'{sar:0.3f}') for sar in sar_range]).transpose()\n",
    "        #pvalue_dfs.append(pvalue_df)\n",
    "        #power = ((pvalue_df > power_pvalue).sum()/trials)\n",
    "        #power.name = str(population)\n",
    "        #power_dfs[baseline_parameters].append(power)\n",
    "    #import pdb; pdb.set_trace()\n",
    "pvalue_df = pd.concat(pvalue_df_pieces)\n",
    "pvalue_df = pvalue_df.set_index(['population', 'parameters', 'hypothesis', 'SAR', 'trial']).squeeze().unstack([0,1,2,3])\n",
    "pvalue_df = (pvalue_df > 0.9).sum()/trials\n",
    "pvalue_df.name = 'power'\n",
    "\n",
    "path = f'./epidemics/fine-sar-trials-{trials}-powers-' + datetime.strftime(datetime.now(), '%d-%H-%M') + '.xlsx'\n",
    "pvalue_df.unstack([1,2]).round(2).to_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.concat(pvalue_df_pieces)\n",
    "raw_df = raw_df.set_index(['population', 'parameters', 'hypothesis', 'SAR', 'trial']).squeeze().unstack([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <th colspan=\"21\" halign=\"left\">{2: 36, 3: 24, 4: 18}</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameters</th>\n",
       "      <th colspan=\"10\" halign=\"left\">(0.8, 0.8, 0.25)</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">(0.8, 0.2, 0.25)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypothesis</th>\n",
       "      <th colspan=\"4\" halign=\"left\">all</th>\n",
       "      <th colspan=\"4\" halign=\"left\">inf-and-SAR-vary</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sus-and-SAR-vary</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">inf-and-SAR-vary</th>\n",
       "      <th colspan=\"4\" halign=\"left\">sus-and-SAR-vary</th>\n",
       "      <th colspan=\"4\" halign=\"left\">only-SAR-varies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAR</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>...</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.7556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>0.8891</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>0.2404</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.8771</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.5046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8257</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.8729</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>0.6401</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>0.7678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.3302</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.9099</td>\n",
       "      <td>0.8587</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.5081</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.7687</td>\n",
       "      <td>0.5159</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>0.7534</td>\n",
       "      <td>0.6472</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>0.3607</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.5799</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.9356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>0.6454</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.9212</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>0.5703</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.8165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.4529</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.7792</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.3861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.7694</td>\n",
       "      <td>0.5726</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.5363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.7642</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>0.3332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.8061</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.5389</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.6143</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.3627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "population {2: 36, 3: 24, 4: 18}                                           \\\n",
       "parameters      (0.8, 0.8, 0.25)                                            \n",
       "hypothesis                   all                         inf-and-SAR-vary   \n",
       "SAR                         0.10    0.15    0.20    0.25             0.10   \n",
       "trial                                                                       \n",
       "0                         0.9606  0.6958  0.1750  0.3960           0.9846   \n",
       "1                         0.9811  0.8471  0.9679  0.6649           0.9997   \n",
       "2                         0.9993  0.9285  0.0622  0.4903           0.9945   \n",
       "3                         0.9890  0.9289  0.6319  0.3302           0.9999   \n",
       "4                         0.9966  0.8906  0.7687  0.5159           0.9988   \n",
       "...                          ...     ...     ...     ...              ...   \n",
       "295                       0.9922  0.8615  0.5306  0.3607           0.9943   \n",
       "296                       0.9924  0.8303  0.9283  0.7750           0.8741   \n",
       "297                       0.9903  0.9926  0.7694  0.5726           1.0000   \n",
       "298                       0.9911  0.7642  0.7056  0.3332           1.0000   \n",
       "299                       0.9999  0.9616  0.4876  0.4451           0.9560   \n",
       "\n",
       "population                                                   ...  \\\n",
       "parameters                                                   ...   \n",
       "hypothesis                         sus-and-SAR-vary          ...   \n",
       "SAR           0.15    0.20    0.25             0.10    0.15  ...   \n",
       "trial                                                        ...   \n",
       "0           0.9801  0.9860  0.7545           0.9977  0.7556  ...   \n",
       "1           0.8847  0.9906  0.0968           0.9997  0.8378  ...   \n",
       "2           0.9657  0.9082  0.2761           0.9968  0.8378  ...   \n",
       "3           0.9955  0.9099  0.8587           0.9939  0.9308  ...   \n",
       "4           0.9678  0.8826  0.2210           0.9944  0.7987  ...   \n",
       "...            ...     ...     ...              ...     ...  ...   \n",
       "295         0.9975  0.5799  0.1523           0.9044  0.9356  ...   \n",
       "296         0.9725  0.7086  0.5703           0.9951  0.8165  ...   \n",
       "297         0.9765  0.6964  0.5825           0.9261  0.5363  ...   \n",
       "298         0.9888  0.5154  0.3462           0.8999  0.7502  ...   \n",
       "299         0.8481  0.9715  0.9438           0.9505  0.8832  ...   \n",
       "\n",
       "population                                                                    \\\n",
       "parameters (0.8, 0.2, 0.25)                                                    \n",
       "hypothesis inf-and-SAR-vary         sus-and-SAR-vary                           \n",
       "SAR                    0.20    0.25             0.10    0.15    0.20    0.25   \n",
       "trial                                                                          \n",
       "0                    0.1244  0.8891           0.9293  0.8558  0.5461  0.3065   \n",
       "1                    0.5315  0.2404           0.9955  0.8771  0.8033  0.8793   \n",
       "2                    0.8257  0.1683           0.8729  0.5884  0.6401  0.8616   \n",
       "3                    0.8607  0.5081           0.9714  0.7296  0.8730  0.0238   \n",
       "4                    0.9621  0.5145           0.9990  0.9923  0.7534  0.6472   \n",
       "...                     ...     ...              ...     ...     ...     ...   \n",
       "295                  0.9398  0.3718           0.9997  0.5781  0.8639  0.6454   \n",
       "296                  0.6939  0.4529           0.7273  0.9746  0.9364  0.7792   \n",
       "297                  0.8805  0.2828           0.9773  0.2323  0.6317  0.3408   \n",
       "298                  0.8435  0.1881           0.9444  0.9978  0.8061  0.8550   \n",
       "299                  0.2306  0.7179           0.9629  0.5950  0.8755  0.5389   \n",
       "\n",
       "population                                          \n",
       "parameters                                          \n",
       "hypothesis only-SAR-varies                          \n",
       "SAR                   0.10    0.15    0.20    0.25  \n",
       "trial                                               \n",
       "0                   0.9996  0.9668  0.6785  0.2314  \n",
       "1                   1.0000  0.9994  0.9626  0.5046  \n",
       "2                   0.8820  0.9873  0.4562  0.7678  \n",
       "3                   0.9899  0.9933  0.9100  0.9998  \n",
       "4                   0.9998  0.9847  0.9617  0.0395  \n",
       "...                    ...     ...     ...     ...  \n",
       "295                 1.0000  0.9858  0.9212  0.1320  \n",
       "296                 0.9985  0.9721  0.9200  0.3861  \n",
       "297                 0.9982  0.9933  0.9096  0.1122  \n",
       "298                 0.9997  0.9873  0.8948  0.2106  \n",
       "299                 0.8111  0.6143  0.6543  0.3627  \n",
       "\n",
       "[300 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th colspan=\"4\" halign=\"left\">(0.8, 0.8, 0.25)</th>\n",
       "      <th colspan=\"4\" halign=\"left\">(0.8, 0.2, 0.25)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>all</th>\n",
       "      <th>inf-and-SAR-vary</th>\n",
       "      <th>sus-and-SAR-vary</th>\n",
       "      <th>only-SAR-varies</th>\n",
       "      <th>all</th>\n",
       "      <th>inf-and-SAR-vary</th>\n",
       "      <th>sus-and-SAR-vary</th>\n",
       "      <th>only-SAR-varies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <th>SAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">{2: 36, 3: 24, 4: 18}</th>\n",
       "      <th>0.10</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "parameters                 (0.8, 0.8, 0.25)                                    \\\n",
       "hypothesis                              all inf-and-SAR-vary sus-and-SAR-vary   \n",
       "population            SAR                                                       \n",
       "{2: 36, 3: 24, 4: 18} 0.10             0.90             0.99             0.88   \n",
       "                      0.15             0.59             0.85             0.47   \n",
       "                      0.20             0.18             0.39             0.16   \n",
       "                      0.25             0.02             0.09             0.04   \n",
       "\n",
       "parameters                                 (0.8, 0.2, 0.25)                   \\\n",
       "hypothesis                 only-SAR-varies              all inf-and-SAR-vary   \n",
       "population            SAR                                                      \n",
       "{2: 36, 3: 24, 4: 18} 0.10            1.00             0.88             0.94   \n",
       "                      0.15            0.85             0.59             0.70   \n",
       "                      0.20            0.40             0.23             0.33   \n",
       "                      0.25            0.08             0.06             0.09   \n",
       "\n",
       "parameters                                                   \n",
       "hypothesis                 sus-and-SAR-vary only-SAR-varies  \n",
       "population            SAR                                    \n",
       "{2: 36, 3: 24, 4: 18} 0.10             0.84            0.96  \n",
       "                      0.15             0.45            0.75  \n",
       "                      0.20             0.18            0.34  \n",
       "                      0.25             0.05            0.10  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_df.unstack([1,2]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_df.unstack([1,2]).round(2).to_excel('./figures/powers/powers_1000_trials_SAR_25_America_fixed_0s_fixed_pop_part2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sus_variance</th>\n",
       "      <th>inf_variance</th>\n",
       "      <th>beta</th>\n",
       "      <th>inf_constant_value</th>\n",
       "      <th>sus_constant_value</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s80</th>\n",
       "      <th>p80</th>\n",
       "      <th>SAR</th>\n",
       "      <th>size</th>\n",
       "      <th>infections</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.02</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.02</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.01</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>399026.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>974.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>397577.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2192.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.80</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.80</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.60</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">8</th>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>198584.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3360000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count  sus_variance  inf_variance   beta  \\\n",
       "s80  p80  SAR  size infections                                                \n",
       "0.02 0.02 0.01 2    1           399026.0        1000.0        1000.0  0.009   \n",
       "                    2              974.0        1000.0        1000.0  0.009   \n",
       "               3    1           397577.0        1000.0        1000.0  0.009   \n",
       "                    2             2192.0        1000.0        1000.0  0.009   \n",
       "                    3              231.0        1000.0        1000.0  0.009   \n",
       "...                                  ...           ...           ...    ...   \n",
       "0.80 0.80 0.60 8    4                0.0           NaN           NaN  0.165   \n",
       "                    5                0.0           NaN           NaN  0.165   \n",
       "                    6                0.0           NaN           NaN  0.165   \n",
       "                    7                0.0           NaN           NaN  0.165   \n",
       "                    8           198584.0           NaN           NaN  0.165   \n",
       "\n",
       "                                inf_constant_value  sus_constant_value  \\\n",
       "s80  p80  SAR  size infections                                           \n",
       "0.02 0.02 0.01 2    1                          NaN                 NaN   \n",
       "                    2                          NaN                 NaN   \n",
       "               3    1                          NaN                 NaN   \n",
       "                    2                          NaN                 NaN   \n",
       "                    3                          NaN                 NaN   \n",
       "...                                            ...                 ...   \n",
       "0.80 0.80 0.60 8    4                          1.0                 1.0   \n",
       "                    5                          1.0                 1.0   \n",
       "                    6                          1.0                 1.0   \n",
       "                    7                          1.0                 1.0   \n",
       "                    8                          1.0                 1.0   \n",
       "\n",
       "                                frequency  \n",
       "s80  p80  SAR  size infections             \n",
       "0.02 0.02 0.01 2    1            0.997565  \n",
       "                    2            0.002435  \n",
       "               3    1            0.993942  \n",
       "                    2            0.005480  \n",
       "                    3            0.000577  \n",
       "...                                   ...  \n",
       "0.80 0.80 0.60 8    4            0.000000  \n",
       "                    5            0.000000  \n",
       "                    6            0.000000  \n",
       "                    7            0.000000  \n",
       "                    8            0.992920  \n",
       "\n",
       "[3360000 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
