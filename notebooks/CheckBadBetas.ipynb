{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7c3824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thayer/covid_households/covid_households\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "%cd ../covid_households/\n",
    "import recipes\n",
    "import utilities\n",
    "import traits\n",
    "\n",
    "import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c1b71",
   "metadata": {},
   "source": [
    "# What is this notebook for?\n",
    "\n",
    "We conduct our simulations over a range of values for each of our three different parameters, $s_{80}$, $p_{80}$, and $\\text{SAR}$. But these parameters are not direct inputs into our model, they are complex expressions of properties of the distributions of relative susceptibility and infectivity ($s_{80}$ and $p_{80}$) in the population or the average risk of infection from a household contact ($\\text{SAR}$). For full information about these parameters, see the Methods and Supplemental Methods sections.\n",
    "\n",
    "To convert these parameters to actual model parameters (the mean & variance of distributions; or $\\beta$, the probability/time of infection) we use numerical methods. For the overwhelming majority of parameter combinations, this works great. But when $p_{80}$ or $s_{80}$ is small and $\\text{SAR}$ is high, we cannot solve for a $\\beta$ that actually produces the desired $\\text{SAR}$. There is so much heterogeneity (and thus so many people that are neglibly infectious or susceptible) that we can't solve for an appropriately high $\\beta$ given that $\\beta < 1$.\n",
    "\n",
    "We want to drop these points of our 3d grid in parameter space so that the likelihood surface does not include points with an unrealistic $\\beta$. To do that, we first have to find every point where the residual from the numerical fit is higher than our tolerance ($10^{-5}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812ed9c",
   "metadata": {},
   "source": [
    "We define the region over which we simulate by enumerating each of its axes. In order to compute in parallel, we also make a `coordinate_stream` generator that yields coordinate pairs for the entire region in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15afc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s80_axis = np.linspace(0.02, 0.80, 40)\n",
    "p80_axis = np.linspace(0.02, 0.80, 40)\n",
    "sar_axis = np.linspace(0.01, 0.60, 60)\n",
    "\n",
    "def coordinate_stream(axis1, axis2, axis3):\n",
    "    for v1 in axis1:\n",
    "        for v2 in axis2:\n",
    "            for v3 in axis3:\n",
    "                yield (v1, v2, v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c19258",
   "metadata": {},
   "source": [
    "Using Python's multiprocessing functionality, we iterate over each point in the region and apply the `calculate_residual` function from `utilities` in order to find the difference between the expected $\\text{SAR}$ and the $\\text{SAR}$ that is actually implied by $\\beta$ and the traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9394f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(4) as p:\n",
    "    total = len(s80_axis) * len(p80_axis) * len(sar_axis)\n",
    "    residuals = list(tqdm.tqdm(\n",
    "        p.imap(utilities.residual_wrapper, coordinate_stream(s80_axis, p80_axis, sar_axis)),\n",
    "        total=total\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ee510",
   "metadata": {},
   "source": [
    "A \"crib\" is a cheat sheet that we use to precalculate the mappings between our parameters and the model parameters we need to simulate forwards in time.\n",
    "\n",
    "We want to mirror its structure but find the cells were the residual is greater than our tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b59ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_crib_copy = model_inputs.S80_P80_SAR_Inputs.beta_crib.copy()\n",
    "beta_crib_copy['residuals'] = list(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec975281",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_crib_copy['bad beta'] = beta_crib_copy['residuals'] > 10e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557780e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_crib_copy[beta_crib_copy['bad beta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b273252",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_crib_copy.to_csv('./problematic_parameter_combinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "((beta_crib_copy[beta_crib_copy['bad beta']].reset_index()['SAR'] < 0.35) & (beta_crib_copy[beta_crib_copy['bad beta']].reset_index()['p80'] > 0.10) &(beta_crib_copy[beta_crib_copy['bad beta']].reset_index()['s80'] > 0.10)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bfc02b",
   "metadata": {},
   "source": [
    "For each bad beta, now that we've made a correction to our recipe for solving for the beta, we want to recalculate the beta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e28584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "beta_crib_copy = pd.read_csv('../data/problematic_parameter_combinations.csv').set_index(['s80','p80','SAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f92674c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(0.02, 0.02, 0.08),\n",
       "            (0.02, 0.02, 0.09),\n",
       "            (0.02, 0.02,  0.1),\n",
       "            (0.02, 0.02, 0.11),\n",
       "            (0.02, 0.02, 0.12),\n",
       "            (0.02, 0.02, 0.13),\n",
       "            (0.02, 0.02, 0.14),\n",
       "            (0.02, 0.02, 0.15),\n",
       "            (0.02, 0.02, 0.16),\n",
       "            (0.02, 0.02, 0.17),\n",
       "            ...\n",
       "            ( 0.8, 0.12, 0.56),\n",
       "            ( 0.8, 0.12, 0.57),\n",
       "            ( 0.8, 0.12, 0.58),\n",
       "            ( 0.8, 0.12, 0.59),\n",
       "            ( 0.8, 0.12,  0.6),\n",
       "            ( 0.8, 0.14, 0.57),\n",
       "            ( 0.8, 0.14, 0.58),\n",
       "            ( 0.8, 0.14, 0.59),\n",
       "            ( 0.8, 0.14,  0.6),\n",
       "            ( 0.8, 0.16,  0.6)],\n",
       "           names=['s80', 'p80', 'SAR'], length=14389)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_view = beta_crib_copy[beta_crib_copy['bad beta']]\n",
    "bad_indices = bad_view.index\n",
    "bad_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0628abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_frame = bad_indices.to_frame()\n",
    "b_frame = b_frame[(b_frame['s80'] != 0.02) & (b_frame['p80'] != 0.02)]\n",
    "b_frame.reset_index(drop=True).to_csv('../data/indices_to_rerun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98d036a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(0.04, 0.04, 0.13),\n",
       "            (0.04, 0.04, 0.14),\n",
       "            (0.04, 0.04, 0.15),\n",
       "            (0.04, 0.04, 0.16),\n",
       "            (0.04, 0.04, 0.17),\n",
       "            (0.04, 0.04, 0.18),\n",
       "            (0.04, 0.04, 0.19),\n",
       "            (0.04, 0.04,  0.2),\n",
       "            (0.04, 0.04, 0.21),\n",
       "            (0.04, 0.04, 0.22),\n",
       "            ...\n",
       "            ( 0.8, 0.12, 0.56),\n",
       "            ( 0.8, 0.12, 0.57),\n",
       "            ( 0.8, 0.12, 0.58),\n",
       "            ( 0.8, 0.12, 0.59),\n",
       "            ( 0.8, 0.12,  0.6),\n",
       "            ( 0.8, 0.14, 0.57),\n",
       "            ( 0.8, 0.14, 0.58),\n",
       "            ( 0.8, 0.14, 0.59),\n",
       "            ( 0.8, 0.14,  0.6),\n",
       "            ( 0.8, 0.16,  0.6)],\n",
       "           names=['s80', 'p80', 'SAR'], length=11320)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frame_test = pd.read_csv('../data/indices_to_rerun.csv')\n",
    "new_frame_test.set_index(['s80', 'p80', 'SAR']).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7f1ccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s80', 'p80', 'SAR']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bad_indices.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad06efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_index_frame = bad_indices.to_frame().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "313b4dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11320"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((bad_index_frame['s80'] > 0.02) & (bad_index_frame['p80'] > 0.02) & (bad_index_frame['SAR'] <= 0.60)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1513020a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36, 0.38, 0.4 , 0.42, 0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56,\n",
       "       0.58, 0.6 , 0.62, 0.64, 0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78,\n",
       "       0.8 ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.linspace(0.36, 0.8, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_betas = []\n",
    "for i in bad_indices:\n",
    "    old_beta = bad_view.loc[i]['beta']\n",
    "    new_beta = model_inputs.S80_P80_SAR_Inputs(*i).to_normal_inputs()['household_beta']\n",
    "    print(old_beta, beta)\n",
    "    new_betas.append(new_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(4) as p:\n",
    "    total = len(bad_indices)\n",
    "    residuals = list(tqdm.tqdm(\n",
    "        p.imap(model_inputs.S80_P80_SAR_Inputs.wrapped_beta_from_point, (i for i in bad_indices)),\n",
    "        total=total\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_betas = residuals.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ab5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_betas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate\n",
    "def SAR(beta, sus, inf, tau):\n",
    "    generalized_period = traits.LognormalTrait(tau.mu + inf.mu + sus.mu, np.sqrt(tau.sigma**2 + inf.sigma**2 + sus.sigma**2)).distribution\n",
    "    integral, abserror = scipy.integrate.quad(lambda x: generalized_period.pdf(x) * np.exp(-1 * beta * x), 0, np.inf)\n",
    "    sar = 1 - integral\n",
    "    return sar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sus = traits.LognormalTrait(model_inputs.S80_P80_SAR_Inputs.s80_crib.loc[0.02].mu, model_inputs.S80_P80_SAR_Inputs.s80_crib.loc[0.02].sigma)\n",
    "inf = traits.LognormalTrait(model_inputs.S80_P80_SAR_Inputs.p80_crib.loc[0.02].mu, model_inputs.S80_P80_SAR_Inputs.p80_crib.loc[0.02].sigma)\n",
    "\n",
    "sus, inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf2362",
   "metadata": {},
   "outputs": [],
   "source": [
    "sus.distribution.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba334d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_solves = []\n",
    "for s80 in model_inputs.S80_P80_SAR_Inputs.s80_crib.index:\n",
    "    trait = traits.LognormalTrait.from_natural_mean_variance(1.0, utilities.lognormal_s80_solve(s80).x[0])\n",
    "    other_solves.append((trait.mu, trait.sigma, trait.distribution.var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs.S80_P80_SAR_Inputs.wrapped_beta_from_point((0.02, 0.02, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs.S80_P80_SAR_Inputs(0.02, 0.02, 0.08).to_normal_inputs(use_beta_crib=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556aa9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tau = utilities.lognormal_calculate_generalized_period(sus, inf)\n",
    "obj = utilities.lognormal_SAR_objective_function_crafter(0.08, g_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.beta_from_sar_and_lognormal_traits(0.08, sus, inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44916633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs.S80_P80_SAR_Inputs.wrapped_beta_from_point((0.02, 0.02, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42116d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_inputs.S80_P80_SAR_Inputs(*(0.02, 0.02, 0.08))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/Users/thayer/covid_households/new_parameters/gillespie-s80-p80-SAR/sizes-2-5/experiment-07-02-16-34'\n",
    "results = recipes.Results.load(dir)\n",
    "results.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162aa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
